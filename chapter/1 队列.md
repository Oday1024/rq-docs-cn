# 队列

任务是一个Python对象，表示在worker（后台）进程中异步调用的函数。只需将对函数及其参数的引用推送到队列中，就可以异步调用任何Python函数。这被称为入队。

## 入队

将任务放在队列中，首先声明一个函数：

```python
import requests

def count_words_at_url(url):
    resp = requests.get(url)
    return len(resp.text.split())
```

注意到什么了？这个函数没什么特别的！任何Python函数调用都可以放在RQ队列中。

将该函数放入队列中，只需执行以下操作：

```python
from rq import Queue
from redis import Redis
from somewhere import count_words_at_url
import time

# 生命Redis连接
redis_conn = Redis()
q = Queue(connection=redis_conn)  # 没有参数意味着使用默认队列

# 延迟执行count_words_at_url('http://nvie.com')
job = q.enqueue(count_words_at_url, 'http://nvie.com')
print(job.result)   # => None

# 稍等一会儿，直到worker完成
time.sleep(2)
print(job.result)   # => 889
```

如果想要将任务放在特定队列中，只需指定其名称：

```python
q = Queue('low', connection=redis_conn)
q.enqueue(count_words_at_url, 'http://nvie.com')
```

注意到上面例子中的`Queue('low')`了吗？你可以使用任何队列名称，因此你可以根据自己的意愿灵活地分配任务。常见的命名模式是使用优先级命名队列（例如：`high`，`medium`，`low`）

此外，你可以添加一些选项来修改队列任务的行为。默认情况下，这些可以从传递给任务函数的kwargs中获取。

- `job_timeout`指定任务中断并标记为`failed`之前的最大运行时间。默认单位为秒，它可以是整数或表示整数的字符串（例如： `2`，`'2'`）。此外，它可以是具有指定单位，包括小时，分钟，秒的字符串（例如`'1h'`，`'3m'`，`'5s'`）。
- `result_ttl`指定成功任务及其结果的保留时间（以秒为单位）。过期的任务将被自动删除。默认为500秒。
- `ttl`指定任务被丢弃之前的最大排队时间。如果指定的值为`-1`表示无限任务ttl，它将无限期运行。默认为-1。
- `failure_ttl` 指定失败任务的保留时间（默认为1年）
- `depends_on` 指定在此任务排队之前必须完成的另一个任务（或任务ID）。
- `job_id` 允许手动指定此任务的 `job_id`
- `at_front`将任务放在队列的*前面*，而不是后面
- `description` 为排队任务添加其他说明。
- `args`和`kwargs`：使用这些来显式地将参数和关键字参数传递给基础任务函数。如果你的函数恰好与RQ具有冲突的参数名称，这很有用，例如`description`或`ttl`。

在最后一种情况下，如果你想传递`description`和`ttl`关键字参数到你的任务而不是RQ的enqueue函数，这就是你要做的：

```python
q = Queue('low', connection=redis_conn)
q.enqueue(count_words_at_url,
          ttl=30,  # ttl将被RQ使用
          args=('http://nvie.com',),
          kwargs={
              'description': 'Function description', # 将被传递给count_words_at_url
              'ttl': 15  # 将被传递给count_words_at_url
          })
```

对于Web进程无法访问在worker中运行的源代码的情况（即代码库X从代码库Y调用延迟函数），你也可以将该函数作为字符串引用传递。

```python
q = Queue('low', connection=redis_conn)
q.enqueue('my_package.my_module.my_func', 3, 4)
```

## 使用队列

除了排队任务外，Queues还有一些有用的方法：

```python
from rq import Queue
from redis import Redis

redis_conn = Redis()
q = Queue(connection=redis_conn)

# 获得队列的任务数
print(len(q))

# 检索任务
queued_job_ids = q.job_ids # 从队列中获取任务ID列表
queued_jobs = q.jobs # 从队列中获取任务实例列表
job = q.fetch_job('my_id') # 返回任务ID为“my_id”的任务实例

# 清空队列, 这将删除队列中的所有任务
q.empty()

# 删除队列
q.delete(delete_jobs=True) # 传递`True`将删除队列中的所有任务
# 队列现在无法使用。它可以通过将任务放入队列中来重新创建。
```

### 设计

使用RQ，你不必预先设置任何队列，也不必指定任何通道，交换，路由规则或诸如此类的东西。你可以将任务放到任何你想要的队列中。只要将任务排队到尚不存在的队列，就会立即创建它。

RQ并没有采用先进的中间商（broker）能够做消息路由给你。你可能会认为这是一个很棒的优势或障碍，取决于你正在解决的问题。

最后，它不是便携式协议，因为它依赖于[pickle](http://docs.python.org/library/pickle.html) 来序列化任务，因此它是一个仅限Python使用的系统。

## 延迟结果

当任务入队时，`queue.enqueue()`方法返回一个`Job`实例。这只不过是一个可用于检查实际任务结果的代理对象。

为此，它具有一个方便的`result`访问者属性，它将在任务尚未完成时返回`None`，或者在任务完成时返回非`None`值（假设任务具有返回值）。

## `@job`装饰器

如果你熟悉Celery，你可能会习惯它的`@task`装饰器。从RQ> = 0.3开始，引入类似的装饰器：

```python
from rq.decorators import job

@job('low', connection=my_redis_conn, timeout=5)
def add(x, y):
    return x + y

job = add.delay(3, 4)
time.sleep(1)
print(job.result)
```

## 绕过worker

出于测试目的，你可以将任务放入队列，而无需将实际执行委派给worker（从版本0.3.1开始提供）。为此，将`is_async=False`参数传递给Queue构造函数：

```sh
>>> q = Queue('low', is_async=False, connection=my_redis_conn)
>>> job = q.enqueue(fib, 8)
>>> job.result
21
```

上面的代码在没有活动工作程序的情况下运行，`fib(8)` 在同一进程中同步执行。你可能知道Celery的这种行为`ALWAYS_EAGER`。但请注意，你仍需要与redis实例建立工作连接，以存储与任务执行和完成相关的状态。

## 任务依赖

RQ 0.4.0中的新功能是链接多个任务执行。执行依赖于其他任务的任务，使用以下`depends_on`参数：

```python
q = Queue('low', connection=my_redis_conn)
report_job = q.enqueue(generate_report)
q.enqueue(send_report, depends_on=report_job)
```

处理任务依赖关系的能力允许你将大型任务拆分为几个较小的任务。依赖于另一个的任务仅在其依赖关系完成时才会排队。

## 任务的注意事项

从技术上讲，你可以将任何Python函数调用放在队列中，但这并不意味着这样做总是明智的。在将任务放入队列之前需要考虑的一些事项：

- 确保该函数`__module__`可由worker导入。特别是，这意味着您无法将`__main__`模块中声明的函数排入队列。
- 确保worker和任务生成器共享完全相同的源代码。
- 确保函数调用不依赖于其上下文。特别是，全局变量是邪恶的（一如既往），但是当工作人员处理它时，函数所依赖的任何状态（例如“当前”用户或“当前”Web请求）都不存在。如果要为“当前”用户完成工作，则应将该用户解析为具体实例，并将对该用户对象的引用作为参数传递给任务。

## 限制

RQ workers只能在实现`fork()`的系统上运行。最值得注意的是，这意味着如果不使用[Windows的Linux子系统](https://docs.microsoft.com/en-us/windows/wsl/about)并在bash shell中运行，就无法在Windows上运行worker。
